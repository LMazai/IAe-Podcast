{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LMazai/IAe-Podcast/blob/main/friendlyEnglish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "unXsYT101xo0"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "#  MVP: Chatbot de Ensino de Inglês para Telegram com IA Gemini, Voz e Lembretes\n",
        "# ==============================================================================\n",
        "#\n",
        "# Objetivo:\n",
        "# Criar um bot funcional (MVP) para Telegram que:\n",
        "# 1. Responde a mensagens de texto e voz usando a IA Gemini do Google.\n",
        "# 2. Permite interação e explicações em Inglês e Português.\n",
        "# 3. Envia mensagens de texto automáticas para incentivar a prática de inglês\n",
        "#    em horários aleatórios (entre 9h e 19h, fuso de Brasilia),\n",
        "#    enquanto o bot estiver rodando.\n",
        "#\n",
        "# Foco:\n",
        "# - Clareza do código e funcionalidade MVP.\n",
        "# - Integração com Telegram, Gemini, STT/TTS.\n",
        "# - Implementação no Google Colab para aprendizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYcOnekU2TO2",
        "outputId": "95073a0b-49b1-4f2c-8604-58c4d119cf7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando bibliotecas... Por favor, aguarde.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m702.3/702.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Bibliotecas instaladas!\n",
            "API Key do Google (Gemini) configurada.\n",
            "Token do Bot do Telegram carregado.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Passo 1: Instalando Bibliotecas e Configurando API Keys\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"Instalando bibliotecas... Por favor, aguarde.\")\n",
        "\n",
        "# python-telegram-bot v20+ (async)\n",
        "!pip install -q python-telegram-bot --upgrade\n",
        "# Para Gemini\n",
        "!pip install -q google-generativeai\n",
        "# Para Text-to-Speech (TTS)\n",
        "!pip install -q pyttsx3 gTTS\n",
        "# Para Speech-to-Text (STT) e conversão de áudio\n",
        "!pip install -q SpeechRecognition pydub\n",
        "# FFmpeg (para pydub e processamento de áudio) e espeak (para pyttsx3 no Linux)\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install -y ffmpeg espeak > /dev/null\n",
        "\n",
        "print(\"Bibliotecas instaladas!\")\n",
        "\n",
        "# --- Configurando as API Keys (Símbolos Secretos do Colab) ---\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Chave da API do Google para Gemini\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"API Key do Google (Gemini) configurada.\")\n",
        "    API_KEY_CONFIGURED = True\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"ERRO: 'GOOGLE_API_KEY' não encontrada nos Símbolos Secretos.\")\n",
        "    API_KEY_CONFIGURED = False\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao configurar API Key Gemini: {e}\")\n",
        "    API_KEY_CONFIGURED = False\n",
        "\n",
        "# Token do Bot do Telegram\n",
        "try:\n",
        "    TELEGRAM_BOT_TOKEN = userdata.get('TELEGRAM_BOT_TOKEN')\n",
        "    if not TELEGRAM_BOT_TOKEN: raise userdata.SecretNotFoundError(\"Token vazio\")\n",
        "    print(\"Token do Bot do Telegram carregado.\")\n",
        "    BOT_TOKEN_CONFIGURED = True\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"ERRO: 'TELEGRAM_BOT_TOKEN' não encontrado ou vazio nos Símbolos Secretos.\")\n",
        "    BOT_TOKEN_CONFIGURED = False\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao carregar Token do Telegram: {e}\")\n",
        "    BOT_TOKEN_CONFIGURED = False\n",
        "\n",
        "if not API_KEY_CONFIGURED or not BOT_TOKEN_CONFIGURED:\n",
        "    print(\"\\nAVISO IMPORTANTE: Configuração de API Key(s) incompleta. O bot pode não funcionar.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ViHiPihDcH8Q"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Passo 2: Lógica do Chatbot com Gemini (AJUSTADA PARA CONCISÃO E AUTO-IDIOMA)\n",
        "# ==============================================================================\n",
        "import google.generativeai as genai\n",
        "import asyncio\n",
        "import re\n",
        "\n",
        "chat_histories = {} # {chat_id: [historico]}\n",
        "# chat_language_preferences REMOVIDO\n",
        "\n",
        "async def get_gemini_response_v3(chat_id: int, user_input_text: str, detected_input_lang: str):\n",
        "    \"\"\"\n",
        "    Gera resposta do Gemini, adaptando-se ao idioma de entrada detectado e focando em concisão.\n",
        "    Retorna (str: texto_da_resposta_para_usuario, str: texto_tts_se_diferente, str: codigo_idioma_resposta_tts)\n",
        "    \"\"\"\n",
        "    if not API_KEY_CONFIGURED:\n",
        "        return \"My AI brain is not connected (API Key missing).\", None, \"en\"\n",
        "    if not user_input_text:\n",
        "        return \"I didn't quite get that. Could you rephrase?\", None, detected_input_lang\n",
        "\n",
        "    history = chat_histories.get(chat_id, [])\n",
        "    response_lang_code_for_tts = detected_input_lang # Resposta no mesmo idioma da entrada\n",
        "\n",
        "    # --- Preparação do Prompt para Gemini ---\n",
        "    prompt_parts = []\n",
        "    tts_text_override = None\n",
        "\n",
        "    if detected_input_lang == \"pt\":\n",
        "        response_lang_code_for_tts = \"pt\"\n",
        "        prompt_parts.append(f\"\"\"Você é 'English Buddy PT', um tutor de inglês AI amigável e CONCISO no Telegram.\n",
        "O usuário enviou a seguinte mensagem em PORTUGUÊS: \"{user_input_text}\"\n",
        "\n",
        "Sua tarefa (responda SEMPRE em PORTUGUÊS e de forma CURTA e SIMPLES):\n",
        "1. Se for uma pergunta sobre como dizer algo em inglês (ex: \"Como se diz 'X' em inglês?\"):\n",
        "    a. Forneça a tradução direta em inglês.\n",
        "    b. Se relevante, dê UMA frase de exemplo CURTA em inglês com sua tradução.\n",
        "    c. EVITE explicações gramaticais longas, a menos que seja crucial para o entendimento da tradução.\n",
        "2. Se for uma dúvida geral sobre aprendizado: responda de forma CURTA, útil e encorajadora.\n",
        "3. Se for um comentário: reconheça BREVEMENTE e, se apropriado, ofereça uma forma CURTA de dizer algo similar em inglês.\n",
        "\n",
        "Exemplo para \"Como se diz 'estou com sono' em inglês?\":\n",
        "\"Em inglês, 'estou com sono' é 'I'm sleepy'. Por exemplo: 'I'm sleepy, I think I'll go to bed.' (Estou com sono, acho que vou para a cama.)\"\n",
        "\n",
        "Sua resposta (CURTA, SIMPLES, em Português, e com uma explicação em ingles):\"\"\")\n",
        "\n",
        "    else: # detected_input_lang == \"en\"\n",
        "        response_lang_code_for_tts = \"en\"\n",
        "        prompt_parts.append(f\"\"\"You are 'English Buddy', a friendly and CONCISE AI English tutor on Telegram.\n",
        "The user sent the following message in ENGLISH: \"{user_input_text}\"\n",
        "\n",
        "Your task (respond ALWAYS in ENGLISH and keep it SHORT and SIMPLE):\n",
        "1. Analyze the user's English for critical errors in grammar or vocabulary that hinder understanding.\n",
        "2. If a CRITICAL error is found:\n",
        "    a. Provide a corrected version.\n",
        "    b. VERY BRIEFLY explain the error (1-2 short sentences). Focus on the correction.\n",
        "    c. Use an encouraging tone. Format: User: \"...\" / Corrected: \"...\" / Tip: \"...\"\n",
        "3. If the English is understandable or has only minor errors:\n",
        "    a. Respond naturally and BRIEFLY to continue the conversation.\n",
        "    b. Avoid unnecessary corrections for minor style issues. Focus on clear communication.\n",
        "4. If asked for a meaning: provide a SHORT definition and ONE example sentence.\n",
        "\n",
        "Example for \"I has a cat.\":\n",
        "\"User: \"I has a cat.\"\n",
        "Corrected: \"I *have* a cat.\"\n",
        "Tip: Nice! For 'I', 'you', 'we', 'they', we use 'have'. For 'he', 'she', 'it', we use 'has'.\"\n",
        "\n",
        "Your response (SHORT, SIMPLE, in English):\"\"\")\n",
        "\n",
        "    # --- Chamada ao Gemini ---\n",
        "    try:\n",
        "        model = genai.GenerativeModel(model_name='gemini-2.0-flash')\n",
        "\n",
        "        current_turn_history = list(history)\n",
        "        current_turn_history.append({'role': 'user', 'parts': [user_input_text]}) # Armazenar o input original no histórico\n",
        "\n",
        "        MAX_HISTORY_TURNS_V3 = 5 # Ainda mais curto para manter o foco\n",
        "        if len(current_turn_history) > MAX_HISTORY_TURNS_V3 * 2:\n",
        "            current_turn_history = current_turn_history[-(MAX_HISTORY_TURNS_V3 * 2):]\n",
        "\n",
        "        # O prompt agora está dentro de `prompt_parts`\n",
        "        final_prompt_for_gemini = [{'role': 'user', 'parts': prompt_parts}]\n",
        "        # Adicionar histórico antes do prompt da tarefa atual, se desejado para contexto mais amplo.\n",
        "        # No entanto, para tarefas de correção/explicação focadas, um prompt direto é melhor.\n",
        "        # Para manter o contexto da conversa, enviamos o `current_turn_history` que inclui o prompt específico no final.\n",
        "        # Corrigindo: o prompt específico deve ser a última interação.\n",
        "        # O histórico é `history`. A interação atual é o `user_input_text` formatado no `prompt_parts`.\n",
        "\n",
        "        # Opção 1: Histórico + Tarefa específica (pode confundir Gemini se o histórico for em outro idioma)\n",
        "        # gemini_payload = history + [{'role': 'user', 'parts': prompt_parts}]\n",
        "\n",
        "        # Opção 2: Focar na tarefa atual, usando o histórico apenas para o Gemini ter um \"conhecimento geral\"\n",
        "        # mas a instrução principal é o `prompt_parts`.\n",
        "        # Para o SDK `generate_content`, ele espera uma lista de turnos.\n",
        "        # A instrução de sistema é o ideal, mas já estamos colocando no prompt.\n",
        "        # Vamos enviar o prompt construído como a única mensagem para focar na tarefa.\n",
        "\n",
        "        print(f\"DEBUG Gemini V3 Req: ChatID {chat_id}, InLang {detected_input_lang}, RespLang {response_lang_code_for_tts}, HistLen (para contexto geral, não enviado diretamente) {len(history)}\")\n",
        "\n",
        "        gen_response = await asyncio.to_thread(\n",
        "            model.generate_content,\n",
        "            # Aqui, passamos o prompt construído que contém a instrução e o texto do usuário.\n",
        "            # Se quisermos que o Gemini use o histórico para respostas mais contextuais (não apenas correção/explicação),\n",
        "            # precisaríamos de uma lógica diferente. Para o MVP atual, focamos na tarefa imediata.\n",
        "            final_prompt_for_gemini,\n",
        "            generation_config=genai.types.GenerationConfig(\n",
        "                candidate_count=1, max_output_tokens=150, # Reduzido para respostas mais curtas\n",
        "                temperature=0.65 # Um pouco mais factual\n",
        "            )\n",
        "        )\n",
        "\n",
        "        response_text_for_user = gen_response.parts[0].text.strip() if gen_response.parts else \\\n",
        "                                (gen_response.text.strip() if hasattr(gen_response, 'text') and gen_response.text else \"\")\n",
        "\n",
        "        if not response_text_for_user:\n",
        "            return \"I had a brief issue generating a response. Could you try again?\", None, detected_input_lang\n",
        "\n",
        "        # Preparar texto para TTS\n",
        "        if response_lang_code_for_tts == \"en\" and \"Corrected:\" in response_text_for_user:\n",
        "            match = re.search(r\"Corrected:\\s*\\\"(.*?)\\\"\", response_text_for_user, re.DOTALL | re.IGNORECASE)\n",
        "            if match:\n",
        "                tts_text_override = match.group(1).replace(\"*\", \"\")\n",
        "        # Para PT, se a resposta contiver \"Em inglês, ... é 'PHRASE'\", TTS lê a PHRASE.\n",
        "        elif response_lang_code_for_tts == \"pt\":\n",
        "             match_en_in_pt_explanation = re.search(r\"Em inglês, [^']*?\\s*é\\s*'([^']*)'\", response_text_for_user, re.IGNORECASE)\n",
        "             if match_en_in_pt_explanation:\n",
        "                 tts_text_override = match_en_in_pt_explanation.group(1)\n",
        "                 # A resposta de voz para a frase em inglês deve ser em inglês\n",
        "                 response_lang_code_for_tts = \"en\" # Sobrescreve o idioma do TTS para a parte em inglês\n",
        "                 print(f\"DEBUG TTS Override: PT explanation, but TTS for English part: '{tts_text_override}' in EN\")\n",
        "\n",
        "\n",
        "        # Atualiza histórico (apenas o input original do usuário e a resposta do bot)\n",
        "        history.append({'role': 'user', 'parts': [user_input_text]})\n",
        "        history.append({'role': 'model', 'parts': [response_text_for_user]})\n",
        "        if len(history) > MAX_HISTORY_TURNS_V3 * 2:\n",
        "            history = history[-(MAX_HISTORY_TURNS_V3 * 2):]\n",
        "        chat_histories[chat_id] = history\n",
        "\n",
        "        return response_text_for_user, tts_text_override, response_lang_code_for_tts\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini API V3 Error (ChatID {chat_id}): {e}\")\n",
        "        return \"I'm having a technical hiccup. Please try again shortly.\", None, detected_input_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_ww4c3PAcPF6"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Passo 3: Funções de Voz (STT e TTS - Sotaque Contextualizado)\n",
        "# ==============================================================================\n",
        "# (A função text_to_speech_v2 e speech_to_text_v2 permanecem as mesmas da Célula 4\n",
        "# da atualização anterior, pois já lidam com sotaques e detecção EN/PT.)\n",
        "# Apenas para garantir que está aqui:\n",
        "\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import asyncio\n",
        "import time # Assegurar que time está importado\n",
        "\n",
        "stt_recognizer_v3 = sr.Recognizer() # Nova instância para clareza, se desejado\n",
        "\n",
        "async def text_to_speech_v3(text: str, chat_id: int, lang_code_and_tld: str = 'en-US', filename_prefix: str = \"tts_audio_v3\"):\n",
        "    \"\"\"\n",
        "    Converte texto para arquivo de áudio MP3 usando gTTS, com sotaque contextualizado.\n",
        "    lang_code_and_tld: ex: 'en-US', 'en-GB', 'pt-BR'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        lang_short = lang_code_and_tld.split('-')[0]\n",
        "        tld_map = {'en-US': 'com', 'en-GB': 'co.uk', 'en-AU': 'com.au', 'pt-BR': 'com.br'}\n",
        "        tld = tld_map.get(lang_code_and_tld, 'com' if lang_short == 'en' else 'com.br') # Default TLDs\n",
        "\n",
        "        unique_id = f\"{chat_id}_{lang_short}_{tld.replace('.', '')}_{int(time.time() * 1000)}\"\n",
        "        output_filename = f\"{filename_prefix}_{unique_id}.mp3\"\n",
        "\n",
        "        print(f\"DEBUG TTS V3: Text='{text[:30]}...', Lang='{lang_short}', TLD='{tld}' for ChatID {chat_id}\")\n",
        "        gtts_obj = gTTS(text=text, lang=lang_short, tld=tld, slow=False)\n",
        "        await asyncio.to_thread(gtts_obj.save, output_filename)\n",
        "        return output_filename\n",
        "    except Exception as e:\n",
        "        print(f\"gTTS V3 Error (ChatID {chat_id}, lang_tld: {lang_code_and_tld}): {e}\")\n",
        "        # Fallback simples se gTTS com TLD falhar\n",
        "        try:\n",
        "            lang_short_fb = lang_code_and_tld.split('-')[0]\n",
        "            fb_filename = f\"{filename_prefix}_{chat_id}_{lang_short_fb}_fb_{int(time.time() * 1000)}.mp3\"\n",
        "            gtts_obj_fb = gTTS(text=text, lang=lang_short_fb, slow=False)\n",
        "            await asyncio.to_thread(gtts_obj_fb.save, fb_filename)\n",
        "            return fb_filename\n",
        "        except Exception as e_fb:\n",
        "            print(f\"gTTS V3 Fallback Error: {e_fb}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "async def speech_to_text_v3(voice_ogg_path: str, chat_id: int):\n",
        "    \"\"\"\n",
        "    Converte áudio OGG para WAV, depois para texto. Tenta EN e PT.\n",
        "    Retorna (str: texto_reconhecido, str: codigo_idioma_detectado ('en' ou 'pt'))\n",
        "    \"\"\"\n",
        "    base, _ = os.path.splitext(voice_ogg_path)\n",
        "    temp_wav_path = f\"{base}_{chat_id}_temp.wav\"\n",
        "    text_en, text_pt = \"\", \"\"\n",
        "\n",
        "    try:\n",
        "        audio = await asyncio.to_thread(AudioSegment.from_ogg, voice_ogg_path)\n",
        "        await asyncio.to_thread(audio.export, temp_wav_path, format=\"wav\")\n",
        "\n",
        "        with sr.AudioFile(temp_wav_path) as source:\n",
        "            audio_data = stt_recognizer_v3.record(source) # Usando a instância v3\n",
        "\n",
        "        # Tenta Inglês\n",
        "        try:\n",
        "            text_en = await asyncio.to_thread(stt_recognizer_v3.recognize_google, audio_data, language=\"en-US\")\n",
        "        except: pass # Silencia erros de reconhecimento individuais\n",
        "        # Tenta Português\n",
        "        try:\n",
        "            text_pt = await asyncio.to_thread(stt_recognizer_v3.recognize_google, audio_data, language=\"pt-BR\")\n",
        "        except: pass\n",
        "\n",
        "        print(f\"STT V3 Results for ChatID {chat_id}: EN='{text_en[:30]}...', PT='{text_pt[:30]}...'\")\n",
        "\n",
        "        # Lógica de decisão de idioma (prioriza o mais longo se ambos reconhecerem, ou o único reconhecido)\n",
        "        # Poderia ser mais robusto com análise de confiança, mas não disponível facilmente.\n",
        "        len_en = len(text_en.split())\n",
        "        len_pt = len(text_pt.split())\n",
        "\n",
        "        if len_en > 0 and len_pt == 0: return text_en, \"en\"\n",
        "        if len_pt > 0 and len_en == 0: return text_pt, \"pt\"\n",
        "        if len_en > 0 and len_pt > 0:\n",
        "            # Se ambos reconheceram, uma heurística simples: o que tiver mais palavras.\n",
        "            # Ou, se um for significativamente mais longo.\n",
        "            if len_pt > len_en + 1: # Se PT for mais que 1 palavra mais longo que EN\n",
        "                return text_pt, \"pt\"\n",
        "            return text_en, \"en\" # Default para EN se comprimentos próximos ou EN maior\n",
        "\n",
        "        print(f\"STT V3: Nenhum idioma reconhecido claramente para ChatID {chat_id}\")\n",
        "        return \"\", None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"STT V3 Error (ChatID {chat_id}, File: {voice_ogg_path}): {e}\")\n",
        "        return \"Error during speech recognition.\", None\n",
        "    finally:\n",
        "        if os.path.exists(temp_wav_path): os.remove(temp_wav_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OjV0ewEocXNm"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Passo 4: Código Principal do Bot do Telegram (SIMPLIFICADO, SEM COMANDOS DE IDIOMA)\n",
        "# ==============================================================================\n",
        "from telegram import Update, ForceReply # ReplyKeyboardMarkup, KeyboardButton REMOVIDOS\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n",
        "from telegram.constants import ParseMode\n",
        "import random\n",
        "import datetime\n",
        "import pytz\n",
        "import os\n",
        "import asyncio\n",
        "# import time # Já importado em células anteriores\n",
        "\n",
        "# --- Armazenamento de IDs e Mensagens Motivacionais (como antes) ---\n",
        "schedulable_chat_ids_v3 = set()\n",
        "reminder_messages_audio_en_v3 = [\n",
        "    \"Hey! Quick English boost: How would you say 'Estou animado para o fim de semana' in English?\",\n",
        "    \"Practice time! Try to describe your favorite food to me in English. 🎤\",\n",
        "    \"A little English a day keeps the language barrier away! What's up?\",\n",
        "    \"Let's make today an English day! Send a voice note about your plans.\"\n",
        "] # Mensagens mais curtas\n",
        "\n",
        "# --- Tarefa Agendada para Envio de Lembretes em ÁUDIO (como antes, mas usando text_to_speech_v3) ---\n",
        "async def scheduled_audio_reminder_task_v3(application: Application):\n",
        "    # (Mesma lógica da função scheduled_audio_reminder_task da atualização anterior,\n",
        "    # mas chamará text_to_speech_v3)\n",
        "    try:\n",
        "        TARGET_TIMEZONE_V3 = pytz.timezone('America/Sao_Paulo')\n",
        "    except pytz.exceptions.UnknownTimeZoneError:\n",
        "        TARGET_TIMEZONE_V3 = pytz.utc\n",
        "    print(f\"INFO: Tarefa de lembretes em ÁUDIO V3 iniciada (fuso: {TARGET_TIMEZONE_V3}).\")\n",
        "    while True:\n",
        "        now_local = datetime.datetime.now(TARGET_TIMEZONE_V3)\n",
        "        if 9 <= now_local.hour <= 19:\n",
        "            await asyncio.sleep(random.randint(75 * 60, 180 * 60)) # Intervalo 1.15h a 3h\n",
        "            current_local_after_sleep = datetime.datetime.now(TARGET_TIMEZONE_V3)\n",
        "            if not (9 <= current_local_after_sleep.hour <= 19): continue\n",
        "\n",
        "            if random.random() < 0.15 and schedulable_chat_ids_v3: # Chance menor (15%)\n",
        "                target_chat_id = random.choice(list(schedulable_chat_ids_v3))\n",
        "                message_text_for_tts = random.choice(reminder_messages_audio_en_v3)\n",
        "                tts_file = await text_to_speech_v3(message_text_for_tts, target_chat_id, lang_code_and_tld='en-US', filename_prefix=\"reminder_audio_v3\")\n",
        "                if tts_file:\n",
        "                    try:\n",
        "                        print(f\"SCHEDULER V3 (Audio): Sending reminder to ChatID {target_chat_id} at {current_local_after_sleep.strftime('%H:%M')}\")\n",
        "                        await application.bot.send_voice(chat_id=target_chat_id, voice=open(tts_file, 'rb'))\n",
        "                    except Exception as e:\n",
        "                        print(f\"SCHEDULER V3 (Audio) Error: {e}\")\n",
        "                        if \"chat not found\" in str(e).lower() or \"bot was blocked\" in str(e).lower():\n",
        "                            schedulable_chat_ids_v3.discard(target_chat_id)\n",
        "                    finally:\n",
        "                        if os.path.exists(tts_file): os.remove(tts_file)\n",
        "        else:\n",
        "            next_run_time = now_local.replace(hour=9, minute=0, second=0, microsecond=0)\n",
        "            if now_local.hour > 19 : next_run_time += datetime.timedelta(days=1)\n",
        "            sleep_duration_seconds = (next_run_time - now_local).total_seconds()\n",
        "            if sleep_duration_seconds <= 0:\n",
        "                next_run_time += datetime.timedelta(days=1)\n",
        "                sleep_duration_seconds = (next_run_time - now_local).total_seconds()\n",
        "                if sleep_duration_seconds <= 0: sleep_duration_seconds = 60 * 60\n",
        "            print(f\"SCHEDULER V3 (Audio): Fora do horário. Dormindo por {sleep_duration_seconds/3600:.1f}h.\")\n",
        "            await asyncio.sleep(max(60, sleep_duration_seconds))\n",
        "\n",
        "\n",
        "# --- Handlers de Comando e Mensagem (Simplificados) ---\n",
        "async def start_handler_v3(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    user = update.effective_user\n",
        "    chat_id = update.effective_chat.id\n",
        "    schedulable_chat_ids_v3.add(chat_id)\n",
        "    # chat_language_preferences REMOVIDO do start\n",
        "\n",
        "    welcome_msg = (\n",
        "        f\"Hello {user.mention_html()}! I'm <b>English Buddy</b> 🤖, your AI practice partner.\\n\\n\"\n",
        "        \"I'll automatically detect if you're speaking 🇬🇧 English or 🇧🇷 Portuguese and respond in the same language.\\n\"\n",
        "        \"My goal is to help you practice! If you write/speak in English, I'll offer corrections. If you ask in Portuguese how to say something, I'll explain and translate.\\n\\n\"\n",
        "        \"Just send me ✍️ text or 🎙️ voice messages to begin.\\n\"\n",
        "        \"I'll also send short motivational voice notes in English sometimes (9am-7pm São Paulo time).\\n\\n\"\n",
        "        \"Type /help for a quick guide.\"\n",
        "    )\n",
        "    # ReplyKeyboardMarkup REMOVIDO\n",
        "    await update.message.reply_html(welcome_msg) # reply_markup REMOVIDO\n",
        "\n",
        "    if chat_id in chat_histories: del chat_histories[chat_id] # Reseta histórico\n",
        "    print(f\"CMD /start V3: User {user.id} (ChatID {chat_id}). Auto-language. Added to schedulable list.\")\n",
        "\n",
        "async def help_handler_v3(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    help_msg = (\n",
        "        \"<b>English Buddy - How I Work</b> 🧐\\n\\n\"\n",
        "        \"<code>/start</code> - Initialize or reset our chat.\\n\"\n",
        "        \"<code>/help</code> - Show this guide.\\n\\n\"\n",
        "        \"🗣️ **Automatic Language Detection:**\\n\"\n",
        "        \"  - If you message in English, I'll reply in English (and correct if needed).\\n\"\n",
        "        \"  - If you message in Portuguese, I'll reply in Portuguese (and translate/explain English phrases if you ask).\\n\\n\"\n",
        "        \"➡️ **Input = Output Type:**\\n\"\n",
        "        \"  - Text message in ➔ Text message out.\\n\"\n",
        "        \"  - Voice message in ➔ Voice message out.\\n\\n\"\n",
        "        \"Just start chatting naturally! My replies aim to be short and clear.\"\n",
        "    )\n",
        "    await update.message.reply_html(help_msg)\n",
        "\n",
        "# Comando /lang REMOVIDO\n",
        "\n",
        "# Função unificada para processar interação (adaptada)\n",
        "async def handle_user_interaction_v3(update: Update, context: ContextTypes.DEFAULT_TYPE, user_input_text: str, detected_input_lang: str, is_voice_input: bool):\n",
        "    chat_id = update.effective_chat.id\n",
        "    schedulable_chat_ids_v3.add(chat_id)\n",
        "\n",
        "    action = \"record_voice\" if is_voice_input else \"typing\"\n",
        "    await context.bot.send_chat_action(chat_id=chat_id, action=action)\n",
        "\n",
        "    response_text_for_user, tts_text_override, response_lang_code_for_tts = await get_gemini_response_v3(chat_id, user_input_text, detected_input_lang)\n",
        "\n",
        "    if is_voice_input:\n",
        "        text_for_tts = tts_text_override if tts_text_override else response_text_for_user\n",
        "        sotaque_tts = \"pt-BR\" if response_lang_code_for_tts == \"pt\" else \"en-US\" # Default sotaque EN para US\n",
        "\n",
        "        print(f\"DEBUG V3 Voice Output: TTS Lang '{response_lang_code_for_tts}', Sotaque '{sotaque_tts}', Text='{text_for_tts[:30]}...'\")\n",
        "        if text_for_tts and \"API Key missing\" not in text_for_tts and \"error\" not in text_for_tts.lower():\n",
        "            tts_file = await text_to_speech_v3(text_for_tts, chat_id, lang_code_and_tld=sotaque_tts)\n",
        "            if tts_file:\n",
        "                try:\n",
        "                    await context.bot.send_voice(chat_id=chat_id, voice=open(tts_file, 'rb'))\n",
        "                except Exception as e_send_voice:\n",
        "                    print(f\"Error sending V3 TTS voice (ChatID {chat_id}): {e_send_voice}\")\n",
        "                    await update.message.reply_text(f\"(Audio failed, text reply instead):\\n{response_text_for_user}\")\n",
        "                finally:\n",
        "                    if os.path.exists(tts_file): os.remove(tts_file)\n",
        "            else:\n",
        "                await update.message.reply_text(f\"(TTS generation failed, text reply instead):\\n{response_text_for_user}\")\n",
        "        else:\n",
        "             await update.message.reply_text(response_text_for_user)\n",
        "    else: # Input texto -> Output texto\n",
        "        # Aqui, poderíamos usar ParseMode.HTML se Gemini for instruído a usar <b> para correções.\n",
        "        # Ex: response_text_for_user = \"Corrected: I <b>went</b> to the store.\"\n",
        "        # await update.message.reply_html(response_text_for_user)\n",
        "        # Por ora, mantendo simples. O Gemini já tem \"Corrected:\" etc.\n",
        "        await update.message.reply_text(response_text_for_user)\n",
        "\n",
        "\n",
        "async def text_message_handler_v3(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    chat_id = update.effective_chat.id\n",
        "    user_text = update.message.text\n",
        "    print(f\"TEXT V3 from ChatID {chat_id}: '{user_text[:50]}...'\")\n",
        "\n",
        "    # Heurística simples para detecção de idioma no texto (pode ser melhorada com langdetect)\n",
        "    # Conta palavras-chave simples em PT. Se presentes, assume PT, senão EN.\n",
        "    pt_keywords = [\" o que \", \" que \", \" como \", \" se \", \" em \", \" para \", \" de \", \" com \", \" um \", \" uma \", \" eu \", \" você \"]\n",
        "    en_keywords = [\" the \", \" is \", \" are \", \" to \", \" and \", \" a \", \" an \", \" in \", \" for \", \" I \", \" you \"]\n",
        "\n",
        "    pt_score = sum(1 for kw in pt_keywords if kw in user_text.lower())\n",
        "    en_score = sum(1 for kw in en_keywords if kw in user_text.lower())\n",
        "\n",
        "    # Pequena preferência para inglês se os scores forem próximos, para incentivar a prática.\n",
        "    detected_lang = \"pt\" if pt_score > en_score + 1 else \"en\"\n",
        "\n",
        "    # Se a frase for muito curta, pode ser difícil detectar, default para 'en'\n",
        "    if len(user_text.split()) < 3 and pt_score == 0 and en_score == 0:\n",
        "        detected_lang = 'en' # Ou poderia ser o último idioma usado, se rastreado.\n",
        "\n",
        "    print(f\"DEBUG Text V3 Handler: Inferred Input Lang for Gemini '{detected_lang}' (PT Score: {pt_score}, EN Score: {en_score})\")\n",
        "    await handle_user_interaction_v3(update, context, user_text, detected_lang, is_voice_input=False)\n",
        "\n",
        "async def voice_message_handler_v3(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    chat_id = update.effective_chat.id\n",
        "    voice = update.message.voice\n",
        "    print(f\"VOICE V3 from ChatID {chat_id}, Duration: {voice.duration}s\")\n",
        "\n",
        "    file_id = voice.file_id\n",
        "    voice_file_obj = await context.bot.get_file(file_id)\n",
        "    temp_ogg_path = f\"voice_input_v3_{chat_id}_{int(time.time())}.ogg\"\n",
        "    await voice_file_obj.download_to_drive(temp_ogg_path)\n",
        "\n",
        "    recognized_text, detected_lang_code = await speech_to_text_v3(temp_ogg_path, chat_id)\n",
        "    if os.path.exists(temp_ogg_path): os.remove(temp_ogg_path)\n",
        "\n",
        "    if not recognized_text or detected_lang_code is None:\n",
        "        reply_err_text = \"Sorry, I couldn't quite make out what you said. Could you try speaking a bit more clearly?\"\n",
        "        await update.message.reply_text(reply_err_text)\n",
        "        sotaque_tts_err = \"en-US\" # Default para erro\n",
        "        if detected_lang_code == \"pt\": sotaque_tts_err = \"pt-BR\" # Se STT retornou algo, mesmo que vazio\n",
        "        tts_err_file = await text_to_speech_v3(reply_err_text, chat_id, lang_code_and_tld=sotaque_tts_err)\n",
        "        if tts_err_file:\n",
        "            try: await context.bot.send_voice(chat_id=chat_id, voice=open(tts_err_file, 'rb'))\n",
        "            finally:\n",
        "                if os.path.exists(tts_err_file): os.remove(tts_err_file)\n",
        "        return\n",
        "\n",
        "    # Não envia mais o \"Heard: ...\" para ser mais direto.\n",
        "    # await update.message.reply_text(f\"Heard (in {detected_lang_code}): \\\"<i>{recognized_text}</i>\\\"\", parse_mode=ParseMode.HTML)\n",
        "\n",
        "    await handle_user_interaction_v3(update, context, recognized_text, detected_lang_code, is_voice_input=True)\n",
        "\n",
        "# --- Função Principal do Bot (V3) ---\n",
        "async def run_bot_v3():\n",
        "    if not BOT_TOKEN_CONFIGURED or not API_KEY_CONFIGURED:\n",
        "        print(\"FATAL: Bot token or Gemini API key not configured. Exiting.\")\n",
        "        return\n",
        "\n",
        "    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()\n",
        "\n",
        "    app.add_handler(CommandHandler(\"start\", start_handler_v3))\n",
        "    app.add_handler(CommandHandler(\"help\", help_handler_v3))\n",
        "    # Comando /lang REMOVIDO\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_message_handler_v3))\n",
        "    app.add_handler(MessageHandler(filters.VOICE, voice_message_handler_v3))\n",
        "\n",
        "    print(\"INFO: Telegram Bot V3 (Auto-Lang, Concise) starting...\")\n",
        "    try:\n",
        "        await app.initialize()\n",
        "        asyncio.create_task(scheduled_audio_reminder_task_v3(app)) # Agendador de áudio\n",
        "        await app.updater.start_polling()\n",
        "        await app.start()\n",
        "        print(\"INFO: Bot V3 is running. Press Ctrl+C (or interrupt Colab cell) to stop.\")\n",
        "        while True: await asyncio.sleep(3600)\n",
        "    except (KeyboardInterrupt, SystemExit): print(\"INFO: Bot V3 shutdown initiated.\")\n",
        "    except Exception as e: print(f\"CRITICAL: Unhandled error in Bot V3 main loop: {e}\")\n",
        "    finally:\n",
        "        print(\"INFO: Shutting down Bot V3 application...\")\n",
        "        if hasattr(app, 'updater') and app.updater and app.updater.running: await app.updater.stop()\n",
        "        # if hasattr(app, 'running') and app.running: await app.stop() # app.stop() não é mais o método para PTB v20+\n",
        "        if hasattr(app, 'stop') and callable(getattr(app, 'stop')): # Checa se o método stop existe e é chamável\n",
        "            await app.stop()\n",
        "        if hasattr(app, 'shutdown'): await app.shutdown()\n",
        "        print(\"INFO: Bot V3 application shut down.\")\n",
        "        await cleanup_temp_files_v3() # Função de limpeza\n",
        "\n",
        "# Função de limpeza (renomeada para V3, mas mesma lógica)\n",
        "async def cleanup_temp_files_v3(directory=\".\", age_seconds=0):\n",
        "    # (Mesmo código da função cleanup_temp_files da atualização anterior)\n",
        "    count = 0\n",
        "    if directory == \".\": directory = \"/content/\"\n",
        "    print(f\"INFO: Cleaning up V3 temporary files in {directory}...\")\n",
        "    for filename in os.listdir(directory):\n",
        "        if (filename.startswith(\"tts_audio_v3_\") and filename.endswith(\".mp3\")) or \\\n",
        "           (filename.startswith(\"reminder_audio_v3_\") and filename.endswith(\".mp3\")) or \\\n",
        "           (filename.startswith(\"voice_input_v3_\") and filename.endswith(\".ogg\")): # Adicionado .ogg\n",
        "            try:\n",
        "                full_path = os.path.join(directory, filename)\n",
        "                os.remove(full_path)\n",
        "                count += 1\n",
        "            except Exception as e: print(f\"Cleanup V3 Error deleting {filename}: {e}\")\n",
        "    if count > 0: print(f\"INFO Cleanup V3: Deleted {count} temporary audio files.\")\n",
        "    else: print(\"INFO Cleanup V3: No temporary audio files to delete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de limpeza (copiada da versão anterior, pois é a mesma)\n",
        "async def cleanup_temp_files(directory=\".\", age_seconds=0): # Deleta todos os .mp3 e .ogg temporários\n",
        "    count = 0\n",
        "    # Garantir que estamos no diretório correto, especialmente no Colab\n",
        "    # O diretório padrão do Colab é /content/\n",
        "    if directory == \".\":\n",
        "        directory = \"/content/\"\n",
        "\n",
        "    print(f\"INFO: Cleaning up temporary files in {directory}...\")\n",
        "    for filename in os.listdir(directory):\n",
        "        if (filename.startswith(\"tts_audio_\") and filename.endswith(\".mp3\")) or \\\n",
        "           (filename.startswith(\"reminder_audio_\") and filename.endswith(\".mp3\")) or \\\n",
        "           (filename.startswith(\"voice_input_\") and filename.endswith(\".ogg\")):\n",
        "            try:\n",
        "                full_path = os.path.join(directory, filename)\n",
        "                os.remove(full_path)\n",
        "                # print(f\"DEBUG Cleanup: Deleted {full_path}\") # Muito verboso\n",
        "                count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Cleanup Error deleting {filename}: {e}\")\n",
        "    if count > 0: print(f\"INFO Cleanup: Deleted {count} temporary audio files.\")\n",
        "    else: print(\"INFO Cleanup: No temporary audio files to delete in this session.\")"
      ],
      "metadata": {
        "id": "g4EFqGyAXYao"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "U6sRkj2ZcZgX",
        "outputId": "a91a175c-5861-48a5-969e-6e62946e7c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Configuration V3 check OK. Starting Telegram bot V3 execution...\n",
            "INFO: Telegram Bot V3 (Auto-Lang, Concise) starting...\n",
            "INFO: Tarefa de lembretes em ÁUDIO V3 iniciada (fuso: America/Sao_Paulo).\n",
            "SCHEDULER V3 (Audio): Fora do horário. Dormindo por 12.2h.\n",
            "INFO: Bot V3 is running. Press Ctrl+C (or interrupt Colab cell) to stop.\n",
            "TEXT V3 from ChatID 7548144916: 'Como se diz eu te amo...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'pt' (PT Score: 2, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang pt, RespLang pt, HistLen (para contexto geral, não enviado diretamente) 6\n",
            "VOICE V3 from ChatID 7548144916, Duration: 2s\n",
            "STT V3 Results for ChatID 7548144916: EN='como se dice El Chicano...', PT='como se diz eu te amo em inglê...'\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang pt, RespLang pt, HistLen (para contexto geral, não enviado diretamente) 8\n",
            "DEBUG V3 Voice Output: TTS Lang 'pt', Sotaque 'pt-BR', Text='\"Eu te amo\" em inglês é \"I lov...'\n",
            "DEBUG TTS V3: Text='\"Eu te amo\" em inglês é \"I lov...', Lang='pt', TLD='com.br' for ChatID 7548144916\n",
            "VOICE V3 from ChatID 7548144916, Duration: 3s\n",
            "STT V3 Results for ChatID 7548144916: EN='como se dice Casio in English...', PT='como se diz cachorro em inglês...'\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, não enviado diretamente) 10\n",
            "DEBUG V3 Voice Output: TTS Lang 'en', Sotaque 'en-US', Text='How do you say 'Casio' in Engl...'\n",
            "DEBUG TTS V3: Text='How do you say 'Casio' in Engl...', Lang='en', TLD='com' for ChatID 7548144916\n",
            "TEXT V3 from ChatID 7548144916: 'Help...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, não enviado diretamente) 10\n",
            "TEXT V3 from ChatID 7548144916: 'How are you...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 1)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, não enviado diretamente) 10\n",
            "TEXT V3 from ChatID 7548144916: 'I’m fine...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, não enviado diretamente) 10\n",
            "TEXT V3 from ChatID 7548144916: 'Yes...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, não enviado diretamente) 10\n",
            "TEXT V3 from ChatID 7548144916: 'Yes...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, não enviado diretamente) 10\n",
            "INFO: Shutting down Bot V3 application...\n",
            "\n",
            "INFO: Bot V3 execution interrupted by user.\n",
            "INFO: Bot V3 execution cell finished.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Passo 5: Executando o Bot do Telegram (Versão 3)\n",
        "# ==============================================================================\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "if API_KEY_CONFIGURED and BOT_TOKEN_CONFIGURED:\n",
        "    print(\"INFO: Configuration V3 check OK. Starting Telegram bot V3 execution...\")\n",
        "    try:\n",
        "        asyncio.run(run_bot_v3()) # Chama a nova função principal V3\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nINFO: Bot V3 execution interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"CRITICAL: Error running the Bot V3 cell: {e}\")\n",
        "    finally:\n",
        "        print(\"INFO: Bot V3 execution cell finished.\")\n",
        "        # A limpeza agora é chamada dentro do `finally` de `run_bot_v3`\n",
        "else:\n",
        "    print(\"ERROR: Bot V3 cannot start due to missing API Key or Bot Token. Check Cell 2 and Colab Secrets.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5jatrCin+OPb7jLuMGxBe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}