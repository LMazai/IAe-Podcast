{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LMazai/IAe-Podcast/blob/main/friendlyEnglish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "unXsYT101xo0"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "#  MVP: Chatbot de Ensino de Ingl√™s para Telegram com IA Gemini, Voz e Lembretes\n",
        "# ==============================================================================\n",
        "#\n",
        "# Objetivo:\n",
        "# Criar um bot funcional (MVP) para Telegram que:\n",
        "# 1. Responde a mensagens de texto e voz usando a IA Gemini do Google.\n",
        "# 2. Permite intera√ß√£o e explica√ß√µes em Ingl√™s e Portugu√™s.\n",
        "# 3. Envia mensagens de texto autom√°ticas para incentivar a pr√°tica de ingl√™s\n",
        "#    em hor√°rios aleat√≥rios (entre 9h e 19h, fuso de Brasilia),\n",
        "#    enquanto o bot estiver rodando.\n",
        "#\n",
        "# Foco:\n",
        "# - Clareza do c√≥digo e funcionalidade MVP.\n",
        "# - Integra√ß√£o com Telegram, Gemini, STT/TTS.\n",
        "# - Implementa√ß√£o no Google Colab para aprendizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYcOnekU2TO2",
        "outputId": "95073a0b-49b1-4f2c-8604-58c4d119cf7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando bibliotecas... Por favor, aguarde.\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m702.3/702.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Bibliotecas instaladas!\n",
            "API Key do Google (Gemini) configurada.\n",
            "Token do Bot do Telegram carregado.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Passo 1: Instalando Bibliotecas e Configurando API Keys\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"Instalando bibliotecas... Por favor, aguarde.\")\n",
        "\n",
        "# python-telegram-bot v20+ (async)\n",
        "!pip install -q python-telegram-bot --upgrade\n",
        "# Para Gemini\n",
        "!pip install -q google-generativeai\n",
        "# Para Text-to-Speech (TTS)\n",
        "!pip install -q pyttsx3 gTTS\n",
        "# Para Speech-to-Text (STT) e convers√£o de √°udio\n",
        "!pip install -q SpeechRecognition pydub\n",
        "# FFmpeg (para pydub e processamento de √°udio) e espeak (para pyttsx3 no Linux)\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install -y ffmpeg espeak > /dev/null\n",
        "\n",
        "print(\"Bibliotecas instaladas!\")\n",
        "\n",
        "# --- Configurando as API Keys (S√≠mbolos Secretos do Colab) ---\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Chave da API do Google para Gemini\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"API Key do Google (Gemini) configurada.\")\n",
        "    API_KEY_CONFIGURED = True\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"ERRO: 'GOOGLE_API_KEY' n√£o encontrada nos S√≠mbolos Secretos.\")\n",
        "    API_KEY_CONFIGURED = False\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao configurar API Key Gemini: {e}\")\n",
        "    API_KEY_CONFIGURED = False\n",
        "\n",
        "# Token do Bot do Telegram\n",
        "try:\n",
        "    TELEGRAM_BOT_TOKEN = userdata.get('TELEGRAM_BOT_TOKEN')\n",
        "    if not TELEGRAM_BOT_TOKEN: raise userdata.SecretNotFoundError(\"Token vazio\")\n",
        "    print(\"Token do Bot do Telegram carregado.\")\n",
        "    BOT_TOKEN_CONFIGURED = True\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"ERRO: 'TELEGRAM_BOT_TOKEN' n√£o encontrado ou vazio nos S√≠mbolos Secretos.\")\n",
        "    BOT_TOKEN_CONFIGURED = False\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao carregar Token do Telegram: {e}\")\n",
        "    BOT_TOKEN_CONFIGURED = False\n",
        "\n",
        "if not API_KEY_CONFIGURED or not BOT_TOKEN_CONFIGURED:\n",
        "    print(\"\\nAVISO IMPORTANTE: Configura√ß√£o de API Key(s) incompleta. O bot pode n√£o funcionar.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ViHiPihDcH8Q"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Passo 2: L√≥gica do Chatbot com Gemini (AJUSTADA PARA CONCIS√ÉO E AUTO-IDIOMA)\n",
        "# ==============================================================================\n",
        "import google.generativeai as genai\n",
        "import asyncio\n",
        "import re\n",
        "\n",
        "chat_histories = {} # {chat_id: [historico]}\n",
        "# chat_language_preferences REMOVIDO\n",
        "\n",
        "async def get_gemini_response_v3(chat_id: int, user_input_text: str, detected_input_lang: str):\n",
        "    \"\"\"\n",
        "    Gera resposta do Gemini, adaptando-se ao idioma de entrada detectado e focando em concis√£o.\n",
        "    Retorna (str: texto_da_resposta_para_usuario, str: texto_tts_se_diferente, str: codigo_idioma_resposta_tts)\n",
        "    \"\"\"\n",
        "    if not API_KEY_CONFIGURED:\n",
        "        return \"My AI brain is not connected (API Key missing).\", None, \"en\"\n",
        "    if not user_input_text:\n",
        "        return \"I didn't quite get that. Could you rephrase?\", None, detected_input_lang\n",
        "\n",
        "    history = chat_histories.get(chat_id, [])\n",
        "    response_lang_code_for_tts = detected_input_lang # Resposta no mesmo idioma da entrada\n",
        "\n",
        "    # --- Prepara√ß√£o do Prompt para Gemini ---\n",
        "    prompt_parts = []\n",
        "    tts_text_override = None\n",
        "\n",
        "    if detected_input_lang == \"pt\":\n",
        "        response_lang_code_for_tts = \"pt\"\n",
        "        prompt_parts.append(f\"\"\"Voc√™ √© 'English Buddy PT', um tutor de ingl√™s AI amig√°vel e CONCISO no Telegram.\n",
        "O usu√°rio enviou a seguinte mensagem em PORTUGU√äS: \"{user_input_text}\"\n",
        "\n",
        "Sua tarefa (responda SEMPRE em PORTUGU√äS e de forma CURTA e SIMPLES):\n",
        "1. Se for uma pergunta sobre como dizer algo em ingl√™s (ex: \"Como se diz 'X' em ingl√™s?\"):\n",
        "    a. Forne√ßa a tradu√ß√£o direta em ingl√™s.\n",
        "    b. Se relevante, d√™ UMA frase de exemplo CURTA em ingl√™s com sua tradu√ß√£o.\n",
        "    c. EVITE explica√ß√µes gramaticais longas, a menos que seja crucial para o entendimento da tradu√ß√£o.\n",
        "2. Se for uma d√∫vida geral sobre aprendizado: responda de forma CURTA, √∫til e encorajadora.\n",
        "3. Se for um coment√°rio: reconhe√ßa BREVEMENTE e, se apropriado, ofere√ßa uma forma CURTA de dizer algo similar em ingl√™s.\n",
        "\n",
        "Exemplo para \"Como se diz 'estou com sono' em ingl√™s?\":\n",
        "\"Em ingl√™s, 'estou com sono' √© 'I'm sleepy'. Por exemplo: 'I'm sleepy, I think I'll go to bed.' (Estou com sono, acho que vou para a cama.)\"\n",
        "\n",
        "Sua resposta (CURTA, SIMPLES, em Portugu√™s, e com uma explica√ß√£o em ingles):\"\"\")\n",
        "\n",
        "    else: # detected_input_lang == \"en\"\n",
        "        response_lang_code_for_tts = \"en\"\n",
        "        prompt_parts.append(f\"\"\"You are 'English Buddy', a friendly and CONCISE AI English tutor on Telegram.\n",
        "The user sent the following message in ENGLISH: \"{user_input_text}\"\n",
        "\n",
        "Your task (respond ALWAYS in ENGLISH and keep it SHORT and SIMPLE):\n",
        "1. Analyze the user's English for critical errors in grammar or vocabulary that hinder understanding.\n",
        "2. If a CRITICAL error is found:\n",
        "    a. Provide a corrected version.\n",
        "    b. VERY BRIEFLY explain the error (1-2 short sentences). Focus on the correction.\n",
        "    c. Use an encouraging tone. Format: User: \"...\" / Corrected: \"...\" / Tip: \"...\"\n",
        "3. If the English is understandable or has only minor errors:\n",
        "    a. Respond naturally and BRIEFLY to continue the conversation.\n",
        "    b. Avoid unnecessary corrections for minor style issues. Focus on clear communication.\n",
        "4. If asked for a meaning: provide a SHORT definition and ONE example sentence.\n",
        "\n",
        "Example for \"I has a cat.\":\n",
        "\"User: \"I has a cat.\"\n",
        "Corrected: \"I *have* a cat.\"\n",
        "Tip: Nice! For 'I', 'you', 'we', 'they', we use 'have'. For 'he', 'she', 'it', we use 'has'.\"\n",
        "\n",
        "Your response (SHORT, SIMPLE, in English):\"\"\")\n",
        "\n",
        "    # --- Chamada ao Gemini ---\n",
        "    try:\n",
        "        model = genai.GenerativeModel(model_name='gemini-2.0-flash')\n",
        "\n",
        "        current_turn_history = list(history)\n",
        "        current_turn_history.append({'role': 'user', 'parts': [user_input_text]}) # Armazenar o input original no hist√≥rico\n",
        "\n",
        "        MAX_HISTORY_TURNS_V3 = 5 # Ainda mais curto para manter o foco\n",
        "        if len(current_turn_history) > MAX_HISTORY_TURNS_V3 * 2:\n",
        "            current_turn_history = current_turn_history[-(MAX_HISTORY_TURNS_V3 * 2):]\n",
        "\n",
        "        # O prompt agora est√° dentro de `prompt_parts`\n",
        "        final_prompt_for_gemini = [{'role': 'user', 'parts': prompt_parts}]\n",
        "        # Adicionar hist√≥rico antes do prompt da tarefa atual, se desejado para contexto mais amplo.\n",
        "        # No entanto, para tarefas de corre√ß√£o/explica√ß√£o focadas, um prompt direto √© melhor.\n",
        "        # Para manter o contexto da conversa, enviamos o `current_turn_history` que inclui o prompt espec√≠fico no final.\n",
        "        # Corrigindo: o prompt espec√≠fico deve ser a √∫ltima intera√ß√£o.\n",
        "        # O hist√≥rico √© `history`. A intera√ß√£o atual √© o `user_input_text` formatado no `prompt_parts`.\n",
        "\n",
        "        # Op√ß√£o 1: Hist√≥rico + Tarefa espec√≠fica (pode confundir Gemini se o hist√≥rico for em outro idioma)\n",
        "        # gemini_payload = history + [{'role': 'user', 'parts': prompt_parts}]\n",
        "\n",
        "        # Op√ß√£o 2: Focar na tarefa atual, usando o hist√≥rico apenas para o Gemini ter um \"conhecimento geral\"\n",
        "        # mas a instru√ß√£o principal √© o `prompt_parts`.\n",
        "        # Para o SDK `generate_content`, ele espera uma lista de turnos.\n",
        "        # A instru√ß√£o de sistema √© o ideal, mas j√° estamos colocando no prompt.\n",
        "        # Vamos enviar o prompt constru√≠do como a √∫nica mensagem para focar na tarefa.\n",
        "\n",
        "        print(f\"DEBUG Gemini V3 Req: ChatID {chat_id}, InLang {detected_input_lang}, RespLang {response_lang_code_for_tts}, HistLen (para contexto geral, n√£o enviado diretamente) {len(history)}\")\n",
        "\n",
        "        gen_response = await asyncio.to_thread(\n",
        "            model.generate_content,\n",
        "            # Aqui, passamos o prompt constru√≠do que cont√©m a instru√ß√£o e o texto do usu√°rio.\n",
        "            # Se quisermos que o Gemini use o hist√≥rico para respostas mais contextuais (n√£o apenas corre√ß√£o/explica√ß√£o),\n",
        "            # precisar√≠amos de uma l√≥gica diferente. Para o MVP atual, focamos na tarefa imediata.\n",
        "            final_prompt_for_gemini,\n",
        "            generation_config=genai.types.GenerationConfig(\n",
        "                candidate_count=1, max_output_tokens=150, # Reduzido para respostas mais curtas\n",
        "                temperature=0.65 # Um pouco mais factual\n",
        "            )\n",
        "        )\n",
        "\n",
        "        response_text_for_user = gen_response.parts[0].text.strip() if gen_response.parts else \\\n",
        "                                (gen_response.text.strip() if hasattr(gen_response, 'text') and gen_response.text else \"\")\n",
        "\n",
        "        if not response_text_for_user:\n",
        "            return \"I had a brief issue generating a response. Could you try again?\", None, detected_input_lang\n",
        "\n",
        "        # Preparar texto para TTS\n",
        "        if response_lang_code_for_tts == \"en\" and \"Corrected:\" in response_text_for_user:\n",
        "            match = re.search(r\"Corrected:\\s*\\\"(.*?)\\\"\", response_text_for_user, re.DOTALL | re.IGNORECASE)\n",
        "            if match:\n",
        "                tts_text_override = match.group(1).replace(\"*\", \"\")\n",
        "        # Para PT, se a resposta contiver \"Em ingl√™s, ... √© 'PHRASE'\", TTS l√™ a PHRASE.\n",
        "        elif response_lang_code_for_tts == \"pt\":\n",
        "             match_en_in_pt_explanation = re.search(r\"Em ingl√™s, [^']*?\\s*√©\\s*'([^']*)'\", response_text_for_user, re.IGNORECASE)\n",
        "             if match_en_in_pt_explanation:\n",
        "                 tts_text_override = match_en_in_pt_explanation.group(1)\n",
        "                 # A resposta de voz para a frase em ingl√™s deve ser em ingl√™s\n",
        "                 response_lang_code_for_tts = \"en\" # Sobrescreve o idioma do TTS para a parte em ingl√™s\n",
        "                 print(f\"DEBUG TTS Override: PT explanation, but TTS for English part: '{tts_text_override}' in EN\")\n",
        "\n",
        "\n",
        "        # Atualiza hist√≥rico (apenas o input original do usu√°rio e a resposta do bot)\n",
        "        history.append({'role': 'user', 'parts': [user_input_text]})\n",
        "        history.append({'role': 'model', 'parts': [response_text_for_user]})\n",
        "        if len(history) > MAX_HISTORY_TURNS_V3 * 2:\n",
        "            history = history[-(MAX_HISTORY_TURNS_V3 * 2):]\n",
        "        chat_histories[chat_id] = history\n",
        "\n",
        "        return response_text_for_user, tts_text_override, response_lang_code_for_tts\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini API V3 Error (ChatID {chat_id}): {e}\")\n",
        "        return \"I'm having a technical hiccup. Please try again shortly.\", None, detected_input_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_ww4c3PAcPF6"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Passo 3: Fun√ß√µes de Voz (STT e TTS - Sotaque Contextualizado)\n",
        "# ==============================================================================\n",
        "# (A fun√ß√£o text_to_speech_v2 e speech_to_text_v2 permanecem as mesmas da C√©lula 4\n",
        "# da atualiza√ß√£o anterior, pois j√° lidam com sotaques e detec√ß√£o EN/PT.)\n",
        "# Apenas para garantir que est√° aqui:\n",
        "\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import asyncio\n",
        "import time # Assegurar que time est√° importado\n",
        "\n",
        "stt_recognizer_v3 = sr.Recognizer() # Nova inst√¢ncia para clareza, se desejado\n",
        "\n",
        "async def text_to_speech_v3(text: str, chat_id: int, lang_code_and_tld: str = 'en-US', filename_prefix: str = \"tts_audio_v3\"):\n",
        "    \"\"\"\n",
        "    Converte texto para arquivo de √°udio MP3 usando gTTS, com sotaque contextualizado.\n",
        "    lang_code_and_tld: ex: 'en-US', 'en-GB', 'pt-BR'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        lang_short = lang_code_and_tld.split('-')[0]\n",
        "        tld_map = {'en-US': 'com', 'en-GB': 'co.uk', 'en-AU': 'com.au', 'pt-BR': 'com.br'}\n",
        "        tld = tld_map.get(lang_code_and_tld, 'com' if lang_short == 'en' else 'com.br') # Default TLDs\n",
        "\n",
        "        unique_id = f\"{chat_id}_{lang_short}_{tld.replace('.', '')}_{int(time.time() * 1000)}\"\n",
        "        output_filename = f\"{filename_prefix}_{unique_id}.mp3\"\n",
        "\n",
        "        print(f\"DEBUG TTS V3: Text='{text[:30]}...', Lang='{lang_short}', TLD='{tld}' for ChatID {chat_id}\")\n",
        "        gtts_obj = gTTS(text=text, lang=lang_short, tld=tld, slow=False)\n",
        "        await asyncio.to_thread(gtts_obj.save, output_filename)\n",
        "        return output_filename\n",
        "    except Exception as e:\n",
        "        print(f\"gTTS V3 Error (ChatID {chat_id}, lang_tld: {lang_code_and_tld}): {e}\")\n",
        "        # Fallback simples se gTTS com TLD falhar\n",
        "        try:\n",
        "            lang_short_fb = lang_code_and_tld.split('-')[0]\n",
        "            fb_filename = f\"{filename_prefix}_{chat_id}_{lang_short_fb}_fb_{int(time.time() * 1000)}.mp3\"\n",
        "            gtts_obj_fb = gTTS(text=text, lang=lang_short_fb, slow=False)\n",
        "            await asyncio.to_thread(gtts_obj_fb.save, fb_filename)\n",
        "            return fb_filename\n",
        "        except Exception as e_fb:\n",
        "            print(f\"gTTS V3 Fallback Error: {e_fb}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "async def speech_to_text_v3(voice_ogg_path: str, chat_id: int):\n",
        "    \"\"\"\n",
        "    Converte √°udio OGG para WAV, depois para texto. Tenta EN e PT.\n",
        "    Retorna (str: texto_reconhecido, str: codigo_idioma_detectado ('en' ou 'pt'))\n",
        "    \"\"\"\n",
        "    base, _ = os.path.splitext(voice_ogg_path)\n",
        "    temp_wav_path = f\"{base}_{chat_id}_temp.wav\"\n",
        "    text_en, text_pt = \"\", \"\"\n",
        "\n",
        "    try:\n",
        "        audio = await asyncio.to_thread(AudioSegment.from_ogg, voice_ogg_path)\n",
        "        await asyncio.to_thread(audio.export, temp_wav_path, format=\"wav\")\n",
        "\n",
        "        with sr.AudioFile(temp_wav_path) as source:\n",
        "            audio_data = stt_recognizer_v3.record(source) # Usando a inst√¢ncia v3\n",
        "\n",
        "        # Tenta Ingl√™s\n",
        "        try:\n",
        "            text_en = await asyncio.to_thread(stt_recognizer_v3.recognize_google, audio_data, language=\"en-US\")\n",
        "        except: pass # Silencia erros de reconhecimento individuais\n",
        "        # Tenta Portugu√™s\n",
        "        try:\n",
        "            text_pt = await asyncio.to_thread(stt_recognizer_v3.recognize_google, audio_data, language=\"pt-BR\")\n",
        "        except: pass\n",
        "\n",
        "        print(f\"STT V3 Results for ChatID {chat_id}: EN='{text_en[:30]}...', PT='{text_pt[:30]}...'\")\n",
        "\n",
        "        # L√≥gica de decis√£o de idioma (prioriza o mais longo se ambos reconhecerem, ou o √∫nico reconhecido)\n",
        "        # Poderia ser mais robusto com an√°lise de confian√ßa, mas n√£o dispon√≠vel facilmente.\n",
        "        len_en = len(text_en.split())\n",
        "        len_pt = len(text_pt.split())\n",
        "\n",
        "        if len_en > 0 and len_pt == 0: return text_en, \"en\"\n",
        "        if len_pt > 0 and len_en == 0: return text_pt, \"pt\"\n",
        "        if len_en > 0 and len_pt > 0:\n",
        "            # Se ambos reconheceram, uma heur√≠stica simples: o que tiver mais palavras.\n",
        "            # Ou, se um for significativamente mais longo.\n",
        "            if len_pt > len_en + 1: # Se PT for mais que 1 palavra mais longo que EN\n",
        "                return text_pt, \"pt\"\n",
        "            return text_en, \"en\" # Default para EN se comprimentos pr√≥ximos ou EN maior\n",
        "\n",
        "        print(f\"STT V3: Nenhum idioma reconhecido claramente para ChatID {chat_id}\")\n",
        "        return \"\", None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"STT V3 Error (ChatID {chat_id}, File: {voice_ogg_path}): {e}\")\n",
        "        return \"Error during speech recognition.\", None\n",
        "    finally:\n",
        "        if os.path.exists(temp_wav_path): os.remove(temp_wav_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OjV0ewEocXNm"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Passo 4: C√≥digo Principal do Bot do Telegram (SIMPLIFICADO, SEM COMANDOS DE IDIOMA)\n",
        "# ==============================================================================\n",
        "from telegram import Update, ForceReply # ReplyKeyboardMarkup, KeyboardButton REMOVIDOS\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n",
        "from telegram.constants import ParseMode\n",
        "import random\n",
        "import datetime\n",
        "import pytz\n",
        "import os\n",
        "import asyncio\n",
        "# import time # J√° importado em c√©lulas anteriores\n",
        "\n",
        "# --- Armazenamento de IDs e Mensagens Motivacionais (como antes) ---\n",
        "schedulable_chat_ids_v3 = set()\n",
        "reminder_messages_audio_en_v3 = [\n",
        "    \"Hey! Quick English boost: How would you say 'Estou animado para o fim de semana' in English?\",\n",
        "    \"Practice time! Try to describe your favorite food to me in English. üé§\",\n",
        "    \"A little English a day keeps the language barrier away! What's up?\",\n",
        "    \"Let's make today an English day! Send a voice note about your plans.\"\n",
        "] # Mensagens mais curtas\n",
        "\n",
        "# --- Tarefa Agendada para Envio de Lembretes em √ÅUDIO (como antes, mas usando text_to_speech_v3) ---\n",
        "async def scheduled_audio_reminder_task_v3(application: Application):\n",
        "    # (Mesma l√≥gica da fun√ß√£o scheduled_audio_reminder_task da atualiza√ß√£o anterior,\n",
        "    # mas chamar√° text_to_speech_v3)\n",
        "    try:\n",
        "        TARGET_TIMEZONE_V3 = pytz.timezone('America/Sao_Paulo')\n",
        "    except pytz.exceptions.UnknownTimeZoneError:\n",
        "        TARGET_TIMEZONE_V3 = pytz.utc\n",
        "    print(f\"INFO: Tarefa de lembretes em √ÅUDIO V3 iniciada (fuso: {TARGET_TIMEZONE_V3}).\")\n",
        "    while True:\n",
        "        now_local = datetime.datetime.now(TARGET_TIMEZONE_V3)\n",
        "        if 9 <= now_local.hour <= 19:\n",
        "            await asyncio.sleep(random.randint(75 * 60, 180 * 60)) # Intervalo 1.15h a 3h\n",
        "            current_local_after_sleep = datetime.datetime.now(TARGET_TIMEZONE_V3)\n",
        "            if not (9 <= current_local_after_sleep.hour <= 19): continue\n",
        "\n",
        "            if random.random() < 0.15 and schedulable_chat_ids_v3: # Chance menor (15%)\n",
        "                target_chat_id = random.choice(list(schedulable_chat_ids_v3))\n",
        "                message_text_for_tts = random.choice(reminder_messages_audio_en_v3)\n",
        "                tts_file = await text_to_speech_v3(message_text_for_tts, target_chat_id, lang_code_and_tld='en-US', filename_prefix=\"reminder_audio_v3\")\n",
        "                if tts_file:\n",
        "                    try:\n",
        "                        print(f\"SCHEDULER V3 (Audio): Sending reminder to ChatID {target_chat_id} at {current_local_after_sleep.strftime('%H:%M')}\")\n",
        "                        await application.bot.send_voice(chat_id=target_chat_id, voice=open(tts_file, 'rb'))\n",
        "                    except Exception as e:\n",
        "                        print(f\"SCHEDULER V3 (Audio) Error: {e}\")\n",
        "                        if \"chat not found\" in str(e).lower() or \"bot was blocked\" in str(e).lower():\n",
        "                            schedulable_chat_ids_v3.discard(target_chat_id)\n",
        "                    finally:\n",
        "                        if os.path.exists(tts_file): os.remove(tts_file)\n",
        "        else:\n",
        "            next_run_time = now_local.replace(hour=9, minute=0, second=0, microsecond=0)\n",
        "            if now_local.hour > 19 : next_run_time += datetime.timedelta(days=1)\n",
        "            sleep_duration_seconds = (next_run_time - now_local).total_seconds()\n",
        "            if sleep_duration_seconds <= 0:\n",
        "                next_run_time += datetime.timedelta(days=1)\n",
        "                sleep_duration_seconds = (next_run_time - now_local).total_seconds()\n",
        "                if sleep_duration_seconds <= 0: sleep_duration_seconds = 60 * 60\n",
        "            print(f\"SCHEDULER V3 (Audio): Fora do hor√°rio. Dormindo por {sleep_duration_seconds/3600:.1f}h.\")\n",
        "            await asyncio.sleep(max(60, sleep_duration_seconds))\n",
        "\n",
        "\n",
        "# --- Handlers de Comando e Mensagem (Simplificados) ---\n",
        "async def start_handler_v3(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    user = update.effective_user\n",
        "    chat_id = update.effective_chat.id\n",
        "    schedulable_chat_ids_v3.add(chat_id)\n",
        "    # chat_language_preferences REMOVIDO do start\n",
        "\n",
        "    welcome_msg = (\n",
        "        f\"Hello {user.mention_html()}! I'm <b>English Buddy</b> ü§ñ, your AI practice partner.\\n\\n\"\n",
        "        \"I'll automatically detect if you're speaking üá¨üáß English or üáßüá∑ Portuguese and respond in the same language.\\n\"\n",
        "        \"My goal is to help you practice! If you write/speak in English, I'll offer corrections. If you ask in Portuguese how to say something, I'll explain and translate.\\n\\n\"\n",
        "        \"Just send me ‚úçÔ∏è text or üéôÔ∏è voice messages to begin.\\n\"\n",
        "        \"I'll also send short motivational voice notes in English sometimes (9am-7pm S√£o Paulo time).\\n\\n\"\n",
        "        \"Type /help for a quick guide.\"\n",
        "    )\n",
        "    # ReplyKeyboardMarkup REMOVIDO\n",
        "    await update.message.reply_html(welcome_msg) # reply_markup REMOVIDO\n",
        "\n",
        "    if chat_id in chat_histories: del chat_histories[chat_id] # Reseta hist√≥rico\n",
        "    print(f\"CMD /start V3: User {user.id} (ChatID {chat_id}). Auto-language. Added to schedulable list.\")\n",
        "\n",
        "async def help_handler_v3(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    help_msg = (\n",
        "        \"<b>English Buddy - How I Work</b> üßê\\n\\n\"\n",
        "        \"<code>/start</code> - Initialize or reset our chat.\\n\"\n",
        "        \"<code>/help</code> - Show this guide.\\n\\n\"\n",
        "        \"üó£Ô∏è **Automatic Language Detection:**\\n\"\n",
        "        \"  - If you message in English, I'll reply in English (and correct if needed).\\n\"\n",
        "        \"  - If you message in Portuguese, I'll reply in Portuguese (and translate/explain English phrases if you ask).\\n\\n\"\n",
        "        \"‚û°Ô∏è **Input = Output Type:**\\n\"\n",
        "        \"  - Text message in ‚ûî Text message out.\\n\"\n",
        "        \"  - Voice message in ‚ûî Voice message out.\\n\\n\"\n",
        "        \"Just start chatting naturally! My replies aim to be short and clear.\"\n",
        "    )\n",
        "    await update.message.reply_html(help_msg)\n",
        "\n",
        "# Comando /lang REMOVIDO\n",
        "\n",
        "# Fun√ß√£o unificada para processar intera√ß√£o (adaptada)\n",
        "async def handle_user_interaction_v3(update: Update, context: ContextTypes.DEFAULT_TYPE, user_input_text: str, detected_input_lang: str, is_voice_input: bool):\n",
        "    chat_id = update.effective_chat.id\n",
        "    schedulable_chat_ids_v3.add(chat_id)\n",
        "\n",
        "    action = \"record_voice\" if is_voice_input else \"typing\"\n",
        "    await context.bot.send_chat_action(chat_id=chat_id, action=action)\n",
        "\n",
        "    response_text_for_user, tts_text_override, response_lang_code_for_tts = await get_gemini_response_v3(chat_id, user_input_text, detected_input_lang)\n",
        "\n",
        "    if is_voice_input:\n",
        "        text_for_tts = tts_text_override if tts_text_override else response_text_for_user\n",
        "        sotaque_tts = \"pt-BR\" if response_lang_code_for_tts == \"pt\" else \"en-US\" # Default sotaque EN para US\n",
        "\n",
        "        print(f\"DEBUG V3 Voice Output: TTS Lang '{response_lang_code_for_tts}', Sotaque '{sotaque_tts}', Text='{text_for_tts[:30]}...'\")\n",
        "        if text_for_tts and \"API Key missing\" not in text_for_tts and \"error\" not in text_for_tts.lower():\n",
        "            tts_file = await text_to_speech_v3(text_for_tts, chat_id, lang_code_and_tld=sotaque_tts)\n",
        "            if tts_file:\n",
        "                try:\n",
        "                    await context.bot.send_voice(chat_id=chat_id, voice=open(tts_file, 'rb'))\n",
        "                except Exception as e_send_voice:\n",
        "                    print(f\"Error sending V3 TTS voice (ChatID {chat_id}): {e_send_voice}\")\n",
        "                    await update.message.reply_text(f\"(Audio failed, text reply instead):\\n{response_text_for_user}\")\n",
        "                finally:\n",
        "                    if os.path.exists(tts_file): os.remove(tts_file)\n",
        "            else:\n",
        "                await update.message.reply_text(f\"(TTS generation failed, text reply instead):\\n{response_text_for_user}\")\n",
        "        else:\n",
        "             await update.message.reply_text(response_text_for_user)\n",
        "    else: # Input texto -> Output texto\n",
        "        # Aqui, poder√≠amos usar ParseMode.HTML se Gemini for instru√≠do a usar <b> para corre√ß√µes.\n",
        "        # Ex: response_text_for_user = \"Corrected: I <b>went</b> to the store.\"\n",
        "        # await update.message.reply_html(response_text_for_user)\n",
        "        # Por ora, mantendo simples. O Gemini j√° tem \"Corrected:\" etc.\n",
        "        await update.message.reply_text(response_text_for_user)\n",
        "\n",
        "\n",
        "async def text_message_handler_v3(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    chat_id = update.effective_chat.id\n",
        "    user_text = update.message.text\n",
        "    print(f\"TEXT V3 from ChatID {chat_id}: '{user_text[:50]}...'\")\n",
        "\n",
        "    # Heur√≠stica simples para detec√ß√£o de idioma no texto (pode ser melhorada com langdetect)\n",
        "    # Conta palavras-chave simples em PT. Se presentes, assume PT, sen√£o EN.\n",
        "    pt_keywords = [\" o que \", \" que \", \" como \", \" se \", \" em \", \" para \", \" de \", \" com \", \" um \", \" uma \", \" eu \", \" voc√™ \"]\n",
        "    en_keywords = [\" the \", \" is \", \" are \", \" to \", \" and \", \" a \", \" an \", \" in \", \" for \", \" I \", \" you \"]\n",
        "\n",
        "    pt_score = sum(1 for kw in pt_keywords if kw in user_text.lower())\n",
        "    en_score = sum(1 for kw in en_keywords if kw in user_text.lower())\n",
        "\n",
        "    # Pequena prefer√™ncia para ingl√™s se os scores forem pr√≥ximos, para incentivar a pr√°tica.\n",
        "    detected_lang = \"pt\" if pt_score > en_score + 1 else \"en\"\n",
        "\n",
        "    # Se a frase for muito curta, pode ser dif√≠cil detectar, default para 'en'\n",
        "    if len(user_text.split()) < 3 and pt_score == 0 and en_score == 0:\n",
        "        detected_lang = 'en' # Ou poderia ser o √∫ltimo idioma usado, se rastreado.\n",
        "\n",
        "    print(f\"DEBUG Text V3 Handler: Inferred Input Lang for Gemini '{detected_lang}' (PT Score: {pt_score}, EN Score: {en_score})\")\n",
        "    await handle_user_interaction_v3(update, context, user_text, detected_lang, is_voice_input=False)\n",
        "\n",
        "async def voice_message_handler_v3(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    chat_id = update.effective_chat.id\n",
        "    voice = update.message.voice\n",
        "    print(f\"VOICE V3 from ChatID {chat_id}, Duration: {voice.duration}s\")\n",
        "\n",
        "    file_id = voice.file_id\n",
        "    voice_file_obj = await context.bot.get_file(file_id)\n",
        "    temp_ogg_path = f\"voice_input_v3_{chat_id}_{int(time.time())}.ogg\"\n",
        "    await voice_file_obj.download_to_drive(temp_ogg_path)\n",
        "\n",
        "    recognized_text, detected_lang_code = await speech_to_text_v3(temp_ogg_path, chat_id)\n",
        "    if os.path.exists(temp_ogg_path): os.remove(temp_ogg_path)\n",
        "\n",
        "    if not recognized_text or detected_lang_code is None:\n",
        "        reply_err_text = \"Sorry, I couldn't quite make out what you said. Could you try speaking a bit more clearly?\"\n",
        "        await update.message.reply_text(reply_err_text)\n",
        "        sotaque_tts_err = \"en-US\" # Default para erro\n",
        "        if detected_lang_code == \"pt\": sotaque_tts_err = \"pt-BR\" # Se STT retornou algo, mesmo que vazio\n",
        "        tts_err_file = await text_to_speech_v3(reply_err_text, chat_id, lang_code_and_tld=sotaque_tts_err)\n",
        "        if tts_err_file:\n",
        "            try: await context.bot.send_voice(chat_id=chat_id, voice=open(tts_err_file, 'rb'))\n",
        "            finally:\n",
        "                if os.path.exists(tts_err_file): os.remove(tts_err_file)\n",
        "        return\n",
        "\n",
        "    # N√£o envia mais o \"Heard: ...\" para ser mais direto.\n",
        "    # await update.message.reply_text(f\"Heard (in {detected_lang_code}): \\\"<i>{recognized_text}</i>\\\"\", parse_mode=ParseMode.HTML)\n",
        "\n",
        "    await handle_user_interaction_v3(update, context, recognized_text, detected_lang_code, is_voice_input=True)\n",
        "\n",
        "# --- Fun√ß√£o Principal do Bot (V3) ---\n",
        "async def run_bot_v3():\n",
        "    if not BOT_TOKEN_CONFIGURED or not API_KEY_CONFIGURED:\n",
        "        print(\"FATAL: Bot token or Gemini API key not configured. Exiting.\")\n",
        "        return\n",
        "\n",
        "    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()\n",
        "\n",
        "    app.add_handler(CommandHandler(\"start\", start_handler_v3))\n",
        "    app.add_handler(CommandHandler(\"help\", help_handler_v3))\n",
        "    # Comando /lang REMOVIDO\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_message_handler_v3))\n",
        "    app.add_handler(MessageHandler(filters.VOICE, voice_message_handler_v3))\n",
        "\n",
        "    print(\"INFO: Telegram Bot V3 (Auto-Lang, Concise) starting...\")\n",
        "    try:\n",
        "        await app.initialize()\n",
        "        asyncio.create_task(scheduled_audio_reminder_task_v3(app)) # Agendador de √°udio\n",
        "        await app.updater.start_polling()\n",
        "        await app.start()\n",
        "        print(\"INFO: Bot V3 is running. Press Ctrl+C (or interrupt Colab cell) to stop.\")\n",
        "        while True: await asyncio.sleep(3600)\n",
        "    except (KeyboardInterrupt, SystemExit): print(\"INFO: Bot V3 shutdown initiated.\")\n",
        "    except Exception as e: print(f\"CRITICAL: Unhandled error in Bot V3 main loop: {e}\")\n",
        "    finally:\n",
        "        print(\"INFO: Shutting down Bot V3 application...\")\n",
        "        if hasattr(app, 'updater') and app.updater and app.updater.running: await app.updater.stop()\n",
        "        # if hasattr(app, 'running') and app.running: await app.stop() # app.stop() n√£o √© mais o m√©todo para PTB v20+\n",
        "        if hasattr(app, 'stop') and callable(getattr(app, 'stop')): # Checa se o m√©todo stop existe e √© cham√°vel\n",
        "            await app.stop()\n",
        "        if hasattr(app, 'shutdown'): await app.shutdown()\n",
        "        print(\"INFO: Bot V3 application shut down.\")\n",
        "        await cleanup_temp_files_v3() # Fun√ß√£o de limpeza\n",
        "\n",
        "# Fun√ß√£o de limpeza (renomeada para V3, mas mesma l√≥gica)\n",
        "async def cleanup_temp_files_v3(directory=\".\", age_seconds=0):\n",
        "    # (Mesmo c√≥digo da fun√ß√£o cleanup_temp_files da atualiza√ß√£o anterior)\n",
        "    count = 0\n",
        "    if directory == \".\": directory = \"/content/\"\n",
        "    print(f\"INFO: Cleaning up V3 temporary files in {directory}...\")\n",
        "    for filename in os.listdir(directory):\n",
        "        if (filename.startswith(\"tts_audio_v3_\") and filename.endswith(\".mp3\")) or \\\n",
        "           (filename.startswith(\"reminder_audio_v3_\") and filename.endswith(\".mp3\")) or \\\n",
        "           (filename.startswith(\"voice_input_v3_\") and filename.endswith(\".ogg\")): # Adicionado .ogg\n",
        "            try:\n",
        "                full_path = os.path.join(directory, filename)\n",
        "                os.remove(full_path)\n",
        "                count += 1\n",
        "            except Exception as e: print(f\"Cleanup V3 Error deleting {filename}: {e}\")\n",
        "    if count > 0: print(f\"INFO Cleanup V3: Deleted {count} temporary audio files.\")\n",
        "    else: print(\"INFO Cleanup V3: No temporary audio files to delete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o de limpeza (copiada da vers√£o anterior, pois √© a mesma)\n",
        "async def cleanup_temp_files(directory=\".\", age_seconds=0): # Deleta todos os .mp3 e .ogg tempor√°rios\n",
        "    count = 0\n",
        "    # Garantir que estamos no diret√≥rio correto, especialmente no Colab\n",
        "    # O diret√≥rio padr√£o do Colab √© /content/\n",
        "    if directory == \".\":\n",
        "        directory = \"/content/\"\n",
        "\n",
        "    print(f\"INFO: Cleaning up temporary files in {directory}...\")\n",
        "    for filename in os.listdir(directory):\n",
        "        if (filename.startswith(\"tts_audio_\") and filename.endswith(\".mp3\")) or \\\n",
        "           (filename.startswith(\"reminder_audio_\") and filename.endswith(\".mp3\")) or \\\n",
        "           (filename.startswith(\"voice_input_\") and filename.endswith(\".ogg\")):\n",
        "            try:\n",
        "                full_path = os.path.join(directory, filename)\n",
        "                os.remove(full_path)\n",
        "                # print(f\"DEBUG Cleanup: Deleted {full_path}\") # Muito verboso\n",
        "                count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Cleanup Error deleting {filename}: {e}\")\n",
        "    if count > 0: print(f\"INFO Cleanup: Deleted {count} temporary audio files.\")\n",
        "    else: print(\"INFO Cleanup: No temporary audio files to delete in this session.\")"
      ],
      "metadata": {
        "id": "g4EFqGyAXYao"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "U6sRkj2ZcZgX",
        "outputId": "a91a175c-5861-48a5-969e-6e62946e7c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Configuration V3 check OK. Starting Telegram bot V3 execution...\n",
            "INFO: Telegram Bot V3 (Auto-Lang, Concise) starting...\n",
            "INFO: Tarefa de lembretes em √ÅUDIO V3 iniciada (fuso: America/Sao_Paulo).\n",
            "SCHEDULER V3 (Audio): Fora do hor√°rio. Dormindo por 12.2h.\n",
            "INFO: Bot V3 is running. Press Ctrl+C (or interrupt Colab cell) to stop.\n",
            "TEXT V3 from ChatID 7548144916: 'Como se diz eu te amo...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'pt' (PT Score: 2, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang pt, RespLang pt, HistLen (para contexto geral, n√£o enviado diretamente) 6\n",
            "VOICE V3 from ChatID 7548144916, Duration: 2s\n",
            "STT V3 Results for ChatID 7548144916: EN='como se dice El Chicano...', PT='como se diz eu te amo em ingl√™...'\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang pt, RespLang pt, HistLen (para contexto geral, n√£o enviado diretamente) 8\n",
            "DEBUG V3 Voice Output: TTS Lang 'pt', Sotaque 'pt-BR', Text='\"Eu te amo\" em ingl√™s √© \"I lov...'\n",
            "DEBUG TTS V3: Text='\"Eu te amo\" em ingl√™s √© \"I lov...', Lang='pt', TLD='com.br' for ChatID 7548144916\n",
            "VOICE V3 from ChatID 7548144916, Duration: 3s\n",
            "STT V3 Results for ChatID 7548144916: EN='como se dice Casio in English...', PT='como se diz cachorro em ingl√™s...'\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, n√£o enviado diretamente) 10\n",
            "DEBUG V3 Voice Output: TTS Lang 'en', Sotaque 'en-US', Text='How do you say 'Casio' in Engl...'\n",
            "DEBUG TTS V3: Text='How do you say 'Casio' in Engl...', Lang='en', TLD='com' for ChatID 7548144916\n",
            "TEXT V3 from ChatID 7548144916: 'Help...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, n√£o enviado diretamente) 10\n",
            "TEXT V3 from ChatID 7548144916: 'How are you...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 1)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, n√£o enviado diretamente) 10\n",
            "TEXT V3 from ChatID 7548144916: 'I‚Äôm fine...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, n√£o enviado diretamente) 10\n",
            "TEXT V3 from ChatID 7548144916: 'Yes...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, n√£o enviado diretamente) 10\n",
            "TEXT V3 from ChatID 7548144916: 'Yes...'\n",
            "DEBUG Text V3 Handler: Inferred Input Lang for Gemini 'en' (PT Score: 0, EN Score: 0)\n",
            "DEBUG Gemini V3 Req: ChatID 7548144916, InLang en, RespLang en, HistLen (para contexto geral, n√£o enviado diretamente) 10\n",
            "INFO: Shutting down Bot V3 application...\n",
            "\n",
            "INFO: Bot V3 execution interrupted by user.\n",
            "INFO: Bot V3 execution cell finished.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Passo 5: Executando o Bot do Telegram (Vers√£o 3)\n",
        "# ==============================================================================\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "if API_KEY_CONFIGURED and BOT_TOKEN_CONFIGURED:\n",
        "    print(\"INFO: Configuration V3 check OK. Starting Telegram bot V3 execution...\")\n",
        "    try:\n",
        "        asyncio.run(run_bot_v3()) # Chama a nova fun√ß√£o principal V3\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nINFO: Bot V3 execution interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"CRITICAL: Error running the Bot V3 cell: {e}\")\n",
        "    finally:\n",
        "        print(\"INFO: Bot V3 execution cell finished.\")\n",
        "        # A limpeza agora √© chamada dentro do `finally` de `run_bot_v3`\n",
        "else:\n",
        "    print(\"ERROR: Bot V3 cannot start due to missing API Key or Bot Token. Check Cell 2 and Colab Secrets.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5jatrCin+OPb7jLuMGxBe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}